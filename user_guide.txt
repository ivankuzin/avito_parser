Скрипт предназначен для сбора информации с сайта avito.

Окружение:
	python 3.7
	pip install requirements.txt

Параметры:
	--cmd - команда. Программа может выполнять 5 команд: 
		'get_items_urls' - сбор страниц по заданным критериям, делается в первую очередь
		'update_items' - поиск новых объявлений в заданной категории
		'scrap' - сбор информации по списку страниц, полученных первой командой
		'scrap_update' - используется, если какая-то часть страниц была обработана, но по какой-то причине программа аварийно завершилась, либо после апдейта страниц
		'clean_table' - очистка таблицы от мусора и неправильно распознанных элементов для повторной обработки
	--region, --category, --query - регион, категория, строка запроса для сбора данных командой 'get_items_urls'
	--output - out директория
	--proxy - адрес прокси, если нужен 
	--urls_file - путь к файлу, полученному командой get_items_urls для применения команды scrap
	--csv_file - путь к таблице, которую нужно очистить от мусора

Руковоство к использованию:
	1. Сбор страниц по заданным условиям:
		python app.py --cmd='get_items_urls' --region='krasnoyarskiy_kray' --category='avtomobili' --query='toyota'
	2. Сбор данных по полученным страницам:
		python app.py --cmd='scrap' --urls_file='items_urls.txt'
	3. Поиск и скрап новых объявлений:
		python app.py --cmd='update_items' --urls_file='items_urls.txt'
		python app.py --cmd='scrap_update' --urls_file='items_urls.txt'
	4. Очистка от мусора и повторная обработка объявлений, в распознании которых произошла ошибка:
		python app.py --cmd='clean_table' --csv_file='file.csv'
		python app.py --cmd='scrap_update' --urls_file='items_urls.txt'

Проблемы:
	1. Невозможность использования Тор, по причине блокировки его на стороне Авито. Попытаться можно, раскомментировав отмеченный код.
	2. Использование прокси сильно снижает скорость
	3. Из-за плохого интернет соединения могут не успевать прогружаться страницы для распознавания номера телефона.
	4. Столкнулся с тем, что иногда авито меняет теги на сайте, необохдимо переписывать код (функции find_element_by_xpath и tree.xpath)
	5. Необохдим установленный Firefox. В конструкторе класса необходимо изменить путь к exe и к профилю на свой. А также geckodriver в PATH.




